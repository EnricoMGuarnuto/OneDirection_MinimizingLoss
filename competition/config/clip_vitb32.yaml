model:
  name: ViT-B/32
  source: open_clip
  pretrained: true
  checkpoint_path: saved_models/clip_vitb32_finetuned_triplet.pt
  output_dim: 512

data:
  train_dir:    data/train
  gallery_dir:  data/test/gallery
  query_dir:    data/test/query
  img_size: 224
  batch_size: 32
  normalization:
    mean: [0.48145466, 0.4578275, 0.40821073]
    std: [0.26862954, 0.26130258, 0.27577711]
  val_split: 0.1

training:
  num_epochs: 10
  freeze_backbone: false
  lr_backbone: 1e-5
  lr_head: 1e-3
  margin: 0.2
  save_checkpoint:  saved_models/clip_vitb32_finetuned_triplet.pt

retrieval:
  top_k: 10
  output_json:    results_clip_vitb32_finetuned_triplet.json 

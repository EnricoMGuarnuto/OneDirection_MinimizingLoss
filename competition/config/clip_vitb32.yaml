model:
  name: ViT-B/32
  source: open_clip
  pretrained: true
  checkpoint_path: #competition/saved_models/clip_vitb32_trpl.pt
  output_dim: 512

data:
  train_dir:    #competition/data/Data_example/training
  gallery_dir:  #competition/data/Data_example/test/gallery
  query_dir:    #competition/data/Data_example/test/query
  img_size: 224
  batch_size: 32
  normalization:
    mean: [0.48145466, 0.4578275, 0.40821073]
    std: [0.26862954, 0.26130258, 0.27577711]
  val_split: 0.1

training:
  num_epochs: 10
  freeze_backbone: false
  lr_backbone: 1e-5
  lr_head: 1e-3
  margin: 0.2
  save_checkpoint:   #competition/saved_models/clip_vitb32_finetuned.pt

retrieval:
  top_k: 10
  output_json:    #competition/results_clip_vitb32_finetuned.json  
